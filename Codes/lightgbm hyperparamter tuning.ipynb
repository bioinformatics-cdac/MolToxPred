{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a68c6-2a8e-4dc5-943e-449f44117a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#tuning hyperparameters\n",
    "from bayes_opt import BayesianOptimization\n",
    "from skopt  import BayesSearchCV \n",
    "\n",
    "#graph, plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import learning_curve\n",
    "#import scikitplot as skplt\n",
    "from skopt.plots import plot_evaluations\n",
    "\n",
    "#building models\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "import time\n",
    "from lightgbm.basic import LightGBMError\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from statsmodels.graphics.gofplots import qqplot\n",
    "#metrics \n",
    "from sklearn.metrics import roc_auc_score, roc_curve,accuracy_score,log_loss\n",
    "from sklearn.metrics import f1_score,precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_curve,average_precision_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay,balanced_accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f008c2-d8d3-4557-9793-cc8eea0122db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df=pd.read_csv(\"/home/anjali/Desktop/MolTox/statistical_correction/bonferroni/train_test_data_10449_bonferroni.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c0c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(0,inplace=True)\n",
    "df.replace([np.inf, -np.inf], 0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497b563-800d-4a4c-93ce-1a851ca804c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc=pd.read_csv(\"/media/anjali/Data/revised/new_padel_fingerprints_10449/selected/desc_58.csv\",index_col=0)\n",
    "desc=pd.read_csv(\"/media/anjali/Data/revised/new_padel_fingerprints_10449/selected/desc_pearson_0.9.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3566db61-b00d-4018-8379-df339a5e9b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=df[df.columns.difference(desc.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2df5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=categorical.drop('Toxicity',axis=1)\n",
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577512fe-6edd-47de-8ca4-61d691fa9ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical=df[categorical.columns].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594a086d-c3ec-49a9-9b7c-7c58762b35b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f22d04-5ea0-403f-97c7-694cdfce4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['Toxicity']\n",
    "X=df.drop(['Toxicity'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df622d26-1398-479d-a58b-975cfb697d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc7589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select only the numerical columns\n",
    "numerical_columns = X.columns[(X.dtypes == 'float64') & (X.columns != 'IPC')]\n",
    "\n",
    "# Create a DataFrame with only the numerical columns\n",
    "numerical_X = X[numerical_columns]\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the numerical data and transform it for the train set\n",
    "scaled_numerical_X_train = scaler.fit_transform(numerical_X.loc[X_train.index])\n",
    "\n",
    "# Replace the scaled numerical data back into the original DataFrame for the train set\n",
    "X.loc[X_train.index, numerical_columns] = scaled_numerical_X_train\n",
    "\n",
    "# Transform the numerical data for the test set\n",
    "scaled_numerical_X_test = scaler.transform(numerical_X.loc[X_test.index])\n",
    "\n",
    "# Replace the scaled numerical data back into the original DataFrame for the test set\n",
    "X.loc[X_test.index, numerical_columns] = scaled_numerical_X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af98c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([X,y],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc58c58-ef31-42fe-8876-2009f2c40e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "train,test=train_test_split(df,test_size=0.20,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d0f017-26e4-4692-a73f-70d8ee8f22e5",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e11f29-1d00-47f9-a47d-6bc4baaf87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def bayes_parameter_opt_lgb(X_train, y_train, init_round=5, opt_round=10, n_folds=5, random_seed=6, n_estimators=100, output_process=False):\n",
    "    # Prepare data\n",
    "    train_data = lgb.Dataset(data=X_train.copy(), label=y_train.copy(), categorical_feature='auto', params={'verbose': -1})\n",
    "    # Parameters\n",
    "    #callbacks = [lgb.early_stopping(early_stopping)]\n",
    "    \n",
    "    def lgb_eval(learning_rate, num_leaves, max_depth, min_child_samples, min_child_weight, subsample, colsample_bytree,lambda_l2\n",
    "                ):\n",
    "        params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'boosting_type': 'dart',\n",
    "            'verbose': -1,\n",
    "            'learning_rate': max(min(learning_rate, 1), 0),\n",
    "            'num_leaves': int(round(num_leaves)),\n",
    "            'max_depth': int(round(max_depth)),\n",
    "            'min_child_samples': int(round(min_child_samples)),\n",
    "            'min_child_weight': min_child_weight,\n",
    "            'subsample': max(min(subsample, 1), 0),\n",
    "            'colsample_bytree': max(min(colsample_bytree, 1), 0),\n",
    "            'lambda_l2' : max(min(lambda_l2, 1), 0),\n",
    "            'feature_pre_filter': False\n",
    "        }\n",
    "        \n",
    "        cv_result = lgb.cv(params, train_data, nfold=n_folds, seed=random_seed, stratified=True, verbose_eval=False, metrics=['auc'])\n",
    "        return max(cv_result['auc-mean'])\n",
    "   \n",
    "    lgbBO = BayesianOptimization(lgb_eval, {\n",
    "        'learning_rate': (0.001, 0.01),\n",
    "        'num_leaves': (31, 40),\n",
    "        'max_depth': (3, 10),\n",
    "        'min_child_samples': (20, 50),\n",
    "        'min_child_weight': (0.001, 0.1),\n",
    "        'subsample': (0.5, 0.9),\n",
    "        'colsample_bytree': (0.5, 0.9),\n",
    "        'lambda_l2': (0.05, 0.8),  # Set bounds for lambda_l1\n",
    "    }, random_state=200)\n",
    "    \n",
    "    # Bayesian Optimization: Maximize\n",
    "    lgbBO.maximize(init_points=init_round, n_iter=opt_round)\n",
    "    \n",
    "    model_auc = []\n",
    "    for model in range(len(lgbBO.res)):\n",
    "        model_auc.append(lgbBO.res[model]['target'])\n",
    "    \n",
    "    # Return best parameters\n",
    "    return lgbBO.res[pd.Series(model_auc).idxmax()]['target'], lgbBO.res[pd.Series(model_auc).idxmax()]['params']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform Bayesian optimization\n",
    "opt_auc, opt_params = bayes_parameter_opt_lgb(X_train, y_train, init_round=5, opt_round=10, n_folds=5, random_seed=13, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c1ea0-005c-47fb-b132-ea2d2465c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert parameter values to the appropriate types\n",
    "opt_params['num_leaves'] = int(round(opt_params['num_leaves']))\n",
    "opt_params['max_depth'] = int(round(opt_params['max_depth']))\n",
    "opt_params['min_child_samples'] = int(round(opt_params['min_child_samples']))\n",
    "\n",
    "# Set additional parameters\n",
    "opt_params['objective'] = 'binary'\n",
    "opt_params['metric'] = 'auc'\n",
    "opt_params['is_unbalance'] = True\n",
    "opt_params['boost_from_average'] = False\n",
    "\n",
    "# Use the optimized parameters\n",
    "opt_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
